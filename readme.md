<div align="center">

<!-- title -->
<!--lint ignore no-dead-urls-->
# Awesome XAI [![Awesome](https://awesome.re/badge.svg)](https://awesome.re) ![Lint Awesome List](https://github.com/altamiracorp/awesome-xai/workflows/Lint%20Awesome%20List/badge.svg)

<!-- subtitle -->
A curated list of XAI papers, methods, critiques, and resources.

<!-- image -->
<img src="https://github.com/altamiracorp/awesome-xai/blob/master/images/icon.png?raw=true" />

<!-- description -->
Explainable AI (XAI) is a branch of machine learning research which seeks to make various 
ML techniques more interpretable.

</div>

<!-- TOC -->

## Contents
- [Surveys](#surveys)
    - [Surveys](#surveys)
    - [Methods](#methods)
    - [Critiques](#critiques)
- [Books](#books)
- [Open Courses](#open-courses)
- [Repositories](#repositories)


<!-- CONTENT -->
## Papers
<!-- - [Apple](https://apple.com) - Apple as a placeholder. -->
### Surveys

### Methods
* [ALIME](https://link.springer.com/chapter/10.1007/978-3-030-33607-3_49) - Autoencoder Based Approach for Local Interpretability
* [LIME](https://dl.acm.org/doi/abs/10.1145/2939672.2939778) - Local Interpretable Model-Agnostic Explanations
* [Anchors](https://ojs.aaai.org/index.php/AAAI/article/view/11491) - High-Precision Model-Agnostic Explanations
* [BayLIME](https://arxiv.org/abs/2012.03058) - Bayesian local interpretable model-agnostic explanations
* [CMM](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.2710&rep=rep1&type=pdf) - Combined multiple models metalearner
* [DecText](https://dl.acm.org/doi/abs/10.1145/775047.775113) - Extracting decision trees from trained neural networks
* [DeepLIFT](https://ieeexplore-ieee-org.ezproxy.libraries.wright.edu/abstract/document/9352498) - Deep label-specific feature learning for image annotation
* [KL-LIME](https://arxiv.org/abs/1810.02678) - Kullback-Leibler Projections based LIME
* [Krishnan, et. al.](https://www.sciencedirect.com/science/article/abs/pii/S0031320398001812) - Extracting decision trees from trained neural networks
* [GPDT](https://ieeexplore.ieee.org/abstract/document/4938655) - Genetic program to evolve decision trees
* [GradCAM](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html) - Gradient-weighted Class Activation Mapping
* [GradCAM++](https://ieeexplore.ieee.org/abstract/document/8354201/) - Generalized gradient-based visual explanations
* [OptiLIME](https://arxiv.org/abs/2006.05714) - Optimized LIME
* [PDA](https://arxiv.org/abs/1702.04595) - Prediction Difference Analysis: Visualize deep neural network decisions
* [ProfWeight](https://arxiv.org/abs/1807.07506) - Transfer information from deep network to simpler model
* [RETAIN](https://arxiv.org/abs/1608.05745) - Reverse time attention model
* [RISE](https://arxiv.org/abs/1806.07421) - Randomized input sampling for explanation
* [SHAP](https://arxiv.org/abs/1705.07874) - A unified approach to interpretting model predictions
* [SIDU](https://arxiv.org/abs/2101.10710) - Similarity, difference, and uniqueness input perturbation
* [Tree Metrics](https://www.researchgate.net/profile/Edward-George-2/publication/2610587_Making_Sense_of_a_Forest_of_Trees/links/55b1085d08aec0e5f430eb40/Making-Sense-of-a-Forest-of-Trees.pdf) - Making sense of a forest of trees
* [TreeSHAP](https://arxiv.org/abs/1706.06060) Consistent feature attribute for tree ensembles
* [TREPAN](http://www.inf.ufrgs.br/~engel/data/media/file/cmp121/TREPAN_craven.nips96.pdf) - Extracting tree-structured representations of trained networks
* [X-TREPAN](https://arxiv.org/abs/1508.07551) - Adapted etraction of comprehensible decision tree in ANNs



### Critiques

## Books
t
## Open Courses

## Repositories

- [EthicalML/xai](https://github.com/EthicalML/xai) - A toolkit for XAI which is focused exclusively on tabular data. It implements a variety of data and model evaluation techniques.
- [PAIR-code/what-if-tool](https://github.com/PAIR-code/what-if-tool) - A tool for Tensorboard or Notebooks which allows investigating model performance and fairness.
- [slundberg/shap](https://github.com/slundberg/shap) - A python module for using Shapley Additive Explanations.


<!-- END CONTENT -->

## Follow
- [The Institute for Ethical AI & Machine Learning](https://ethical.institute/index.html) - A UK-based research center that performs research into ethical AI/MO, which frequently involves XAI.

Who else should we be following!?

## Contributing

[Contributions of any kind welcome, just follow the guidelines](contributing.md)!

### Contributors
[Thanks goes to these contributors](https://github.com/altamiracorp/awesome-xai/graphs/contributors)!

## License
[CC0 License](license)
